{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c10e7bcc-18f6-46f5-9ed6-cc4c3d0c0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9c4b2ee-f452-4c94-b963-b45e5b825886",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('data/support_tickets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ceac3ed-33e0-4d3c-acb7-df9cd977e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['subject','body', 'queue', 'priority', 'language']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "643e87a3-6a5b-4880-8122-a99b83124c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24749 entries, 0 to 28586\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   subject   24749 non-null  object\n",
      " 1   body      24749 non-null  object\n",
      " 2   queue     24749 non-null  object\n",
      " 3   priority  24749 non-null  object\n",
      " 4   language  24749 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "20ed5544-1b7c-43d3-b0a3-fc0ba3ad0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Class for preprocessing\n",
    "class TicketClassifier:\n",
    "    def __init__(self):\n",
    "\n",
    "        # =========================\n",
    "        # Models\n",
    "        # =========================\n",
    "        self.model_queue = LinearSVC(C=1.0)\n",
    "        self.model_priority = LinearSVC(C=1.0)\n",
    "        self.model_language = LinearSVC(C=1.0)\n",
    "\n",
    "        # =========================\n",
    "        # Vectorizers (SEPARATE!)\n",
    "        # =========================\n",
    "\n",
    "        # For queue & priority (semantic understanding)\n",
    "        self.vectorizer_text = TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=3\n",
    "        )\n",
    "\n",
    "        # For language detection (character patterns)\n",
    "        self.vectorizer_lang = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(3, 5),\n",
    "            min_df=5\n",
    "        )\n",
    "\n",
    "        # Stopwords ONLY for semantic tasks\n",
    "        self.stop_words = set(\n",
    "            stopwords.words(\"english\")\n",
    "        ).union(\n",
    "            stopwords.words(\"german\")\n",
    "        )\n",
    "\n",
    "    # =========================\n",
    "    # Shared text builder\n",
    "    # =========================\n",
    "    def _build_text(self, x):\n",
    "        x = x[['subject', 'body']].dropna().copy()\n",
    "        x['text'] = x['subject'] + ' ' + x['body']\n",
    "        return x['text']\n",
    "\n",
    "    # =========================\n",
    "    # Preprocessing for QUEUE & PRIORITY\n",
    "    # =========================\n",
    "    def _preprocess_semantic(self, texts, fit=False):\n",
    "\n",
    "        # lowercase\n",
    "        texts = texts.str.lower()\n",
    "\n",
    "        # remove punctuation\n",
    "        texts = texts.apply(\n",
    "            lambda t: t.translate(\n",
    "                str.maketrans('', '', string.punctuation)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # remove numbers\n",
    "        texts = texts.apply(\n",
    "            lambda t: ''.join(ch for ch in t if not ch.isdigit())\n",
    "        )\n",
    "\n",
    "        # remove stopwords\n",
    "        texts = texts.apply(\n",
    "            lambda t: ' '.join(\n",
    "                w for w in t.split() if w not in self.stop_words\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if fit:\n",
    "            return self.vectorizer_text.fit_transform(texts)\n",
    "        return self.vectorizer_text.transform(texts)\n",
    "\n",
    "    # =========================\n",
    "    # Preprocessing for LANGUAGE\n",
    "    # =========================\n",
    "    def _preprocess_language(self, texts, fit=False):\n",
    "\n",
    "        # lowercase ONLY (do NOT remove stopwords!)\n",
    "        texts = texts.str.lower()\n",
    "\n",
    "        if fit:\n",
    "            return self.vectorizer_lang.fit_transform(texts)\n",
    "        return self.vectorizer_lang.transform(texts)\n",
    "\n",
    "    # =========================\n",
    "    # Train\n",
    "    # =========================\n",
    "    def train(self, x, y_queue, y_language, y_priority):\n",
    "\n",
    "        texts = self._build_text(x)\n",
    "\n",
    "        # Semantic features\n",
    "        X_sem = self._preprocess_semantic(texts, fit=True)\n",
    "\n",
    "        # Language features\n",
    "        X_lang = self._preprocess_language(texts, fit=True)\n",
    "\n",
    "        # Train models\n",
    "        self.model_queue.fit(X_sem, y_queue)\n",
    "        self.model_priority.fit(X_sem, y_priority)\n",
    "        self.model_language.fit(X_lang, y_language)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # =========================\n",
    "    # Predict\n",
    "    # =========================\n",
    "    def predict(self, x):\n",
    "\n",
    "        texts = self._build_text(x)\n",
    "\n",
    "        X_sem = self._preprocess_semantic(texts, fit=False)\n",
    "        X_lang = self._preprocess_language(texts, fit=False)\n",
    "\n",
    "        queue = self.model_queue.predict(X_sem).tolist()\n",
    "        priority = self.model_priority.predict(X_sem).tolist()\n",
    "        language = self.model_language.predict(X_lang).tolist()\n",
    "\n",
    "        return {\n",
    "            \"Queue\": queue,\n",
    "            \"Language\": language,\n",
    "            \"Priority\": priority\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f15f7f51-2931-431e-9d2f-811ee63ac46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data[['subject','body']].dropna()\n",
    "y_queue= data['queue']\n",
    "y_language= data['language']\n",
    "y_priority= data['priority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "005e6a88-9866-4d27-bcb3-7b818a4b26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= TicketClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d74bac72-987c-42b0-8c1b-a7c41e7c64cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TicketClassifier at 0x7fc5fc953f90>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(x, y_queue, y_language, y_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "861e5204-995e-40fd-83bb-3ab01eb82f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter subject :  Payment is stuck\n",
      "Enter main :  I made a payment yesterday but the amount is still not reflected in my account. The transaction shows pending status. Please resolve this issue at the earliest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Queue': ['Billing and Payments'], 'Language': ['en'], 'Priority': ['medium']}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter subject :  q\n",
      "Enter main :  q\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    subject= input('Enter subject : ')\n",
    "    body= input('Enter main : ')\n",
    "    if subject==\"q\":\n",
    "        break\n",
    "    else:\n",
    "        df= pd.DataFrame([[subject, body]], columns= ['subject','body'])\n",
    "        pred= model.predict(df)\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6140b-cb3b-4efe-b66c-afa40032b7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
